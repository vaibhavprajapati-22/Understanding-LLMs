## Training
To train the tokenizer on custom text corpus :
1. Clone the repository:
  ```sh
  git clone https://github.com/vaibhavprajapati-22/Understanding-LLMs
  cd Understanding-LLMs
  ```
2. Run Tokenizer.py script
  ```sh
  python Tokenizer.py path_text_corpus path_tokenizer merges_count
  ```
